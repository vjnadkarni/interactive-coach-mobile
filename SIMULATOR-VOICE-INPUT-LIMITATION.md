# iOS Simulator Voice Input Limitation

**Date**: November 10, 2025
**Issue**: Microphone button shows "Listening" state but doesn't transcribe speech in iOS Simulator

## Root Cause

**iOS Simulator has limited or non-functional speech recognition support.**

This is a known Apple limitation, not an issue with our app code. The Speech Recognition framework (`speech_to_text` package) has the following limitations in the simulator:

1. **Microphone Pass-Through Issues**: The simulator relies on your Mac's microphone, which may not be properly configured or passed through
2. **Speech Framework Limitations**: Apple's Speech Recognition API is designed primarily for physical iOS devices
3. **On-Device Processing**: Modern iOS devices use on-device ML models for speech recognition, which aren't fully emulated in the simulator

## What Works in Simulator ‚úÖ

1. ‚úÖ **Text Input** - Type messages and get responses (fully functional)
2. ‚úÖ **Text-to-Speech (TTS)** - Hera speaks responses with ElevenLabs voice (works perfectly)
3. ‚úÖ **Backend API** - Chat streaming, authentication, database (all working)
4. ‚úÖ **UI/Navigation** - All screens, buttons, navigation (fully functional)
5. ‚úÖ **Microphone Button** - Visual feedback shows "Listening" state correctly

## What Doesn't Work in Simulator ‚ùå

1. ‚ùå **Speech-to-Text (STT)** - Voice input doesn't transcribe speech
2. ‚ùå **Microphone Audio Capture** - Simulator doesn't reliably capture Mac microphone input for Speech Recognition

## Solution: Test on Physical Device

**Voice input (speech recognition) works perfectly on physical iOS devices.**

### To Test Voice Input:

**Option 1: iPhone 12 (Currently Connected)**
- Device ID: `00008101-001D44303C08801E`
- Status: Connected but has pairing issue (0xE800001A)
- Action needed: Re-pair device with Mac, ensure unlocked and trusted

**Option 2: Any Other Physical iOS Device**
- iPhone, iPad, or iPod touch running iOS 13.0+
- Connect via USB cable
- Ensure device is unlocked and trusted
- Run: `flutter run -d <device-id>`

## Testing Strategy

### Simulator Testing (Current Workflow)
Use the iOS Simulator for:
- ‚úÖ UI/UX testing
- ‚úÖ Text input testing
- ‚úÖ Backend API integration testing
- ‚úÖ TTS (speech output) testing
- ‚úÖ Navigation and state management testing
- ‚úÖ Hot reload during development

### Physical Device Testing (For Voice Input)
Use a physical iPhone/iPad for:
- ‚úÖ Speech recognition (STT) testing
- ‚úÖ Microphone permissions testing
- ‚úÖ Real-world voice input accuracy testing
- ‚úÖ Full end-to-end user experience testing

## Current Status

### Simulator ‚úÖ
- **App deployed**: iPhone 16 Pro Simulator
- **Text input**: Working perfectly
- **TTS output**: Working perfectly
- **Backend**: All APIs functional
- **Voice input**: Not functional (expected simulator limitation)

### Physical Device ‚è≥
- **iPhone 12 detected**: Yes
- **Connection status**: Pairing error (0xE800001A)
- **Next step**: Fix device pairing to enable physical device testing

## Workaround for Simulator Voice Testing

If you want to test the speech recognition code flow in the simulator without actual voice input, you can:

1. **Use Text Input**: Type your messages - the backend responds identically
2. **Mock Speech Results**: Modify `chat_screen.dart` to simulate speech transcripts (development only)
3. **Test on Physical Device**: The recommended approach for voice input testing

## Recommendation

**For development:**
- ‚úÖ Continue using iOS Simulator with text input
- ‚úÖ All features except voice input can be tested in simulator
- ‚úÖ Voice input automatically works when deployed to physical device (no code changes needed)

**For voice input testing:**
- ‚è≥ Fix iPhone 12 pairing issue
- ‚úÖ Or test on another physical iOS device
- ‚úÖ Voice recognition will work immediately on real device (iOS native speech has automatic punctuation!)

## Technical Details

### Speech Recognition Initialization
```dart
// In chat_screen.dart
Future<void> _initSpeech() async {
  _speechAvailable = await _speech.initialize(
    onStatus: (status) => print('üé§ [ChatScreen] Speech status: $status'),
    onError: (error) => print('‚ùå [ChatScreen] Speech error: $error'),
  );
  setState(() {});
  print('üé§ [ChatScreen] Speech available: $_speechAvailable');
}
```

### iOS Native Speech Features
- ‚úÖ Automatic punctuation (periods, commas, questions, exclamations)
- ‚úÖ Automatic capitalization
- ‚úÖ High accuracy (Apple-quality recognition)
- ‚úÖ On-device processing (privacy-focused)
- ‚úÖ Works offline (on-device ML models)

### Simulator vs Physical Device

| Feature | Simulator | Physical Device |
|---------|-----------|-----------------|
| Text Input | ‚úÖ Works | ‚úÖ Works |
| Voice Input (STT) | ‚ùå Limited/Non-functional | ‚úÖ Works perfectly |
| TTS Output | ‚úÖ Works | ‚úÖ Works |
| Microphone Access | ‚ö†Ô∏è Mac microphone (unreliable) | ‚úÖ Device microphone |
| Speech Recognition | ‚ùå Framework limitations | ‚úÖ Full iOS Speech API |
| Punctuation | N/A | ‚úÖ Automatic |
| Capitalization | N/A | ‚úÖ Automatic |

## Conclusion

The microphone "Listening" state without transcription is **expected behavior in iOS Simulator** due to Apple's Speech Recognition framework limitations. This is not a bug in our app.

**The solution is to test voice input on a physical iOS device**, where Apple's native speech recognition works perfectly with automatic punctuation and capitalization.

All other app functionality (text input, TTS, backend API, UI) works perfectly in the simulator and is fully testable there.
